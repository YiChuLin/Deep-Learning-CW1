{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Copy_of_460cw1_2020_v3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c1e9eaaa53e64837985eac1c1dbc17b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_084c1452157f43a29ee0f14bf02dd744",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d546dee506f74f16a65459ff85c0a55f",
              "IPY_MODEL_1298168d3ba8432ab950690f26ca6787"
            ]
          }
        },
        "084c1452157f43a29ee0f14bf02dd744": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d546dee506f74f16a65459ff85c0a55f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0fbd01f094164c159430e78162e9f655",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2f5e287bc8ba4500ad9285c6efc1e138"
          }
        },
        "1298168d3ba8432ab950690f26ca6787": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_df76a81266bc40b68f64fca82072d625",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "170500096it [00:02, 76720965.06it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3f19db64f4b54dde88854f0f85bd0079"
          }
        },
        "0fbd01f094164c159430e78162e9f655": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2f5e287bc8ba4500ad9285c6efc1e138": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df76a81266bc40b68f64fca82072d625": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3f19db64f4b54dde88854f0f85bd0079": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNbft_rqqa4a",
        "colab_type": "text"
      },
      "source": [
        "# Coursework1: Convolutional Neural Networks "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8B3i_sYLqa4d",
        "colab_type": "text"
      },
      "source": [
        "## instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGKFW3UUqa4f",
        "colab_type": "text"
      },
      "source": [
        "Please submit a version of this notebook containing your answers **together with your trained model** on CATe as CW2.zip. Write your answers in the cells below each question."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTw8jqDKqa4h",
        "colab_type": "text"
      },
      "source": [
        "### Setting up working environment "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mx9Z_y9Hqa4j",
        "colab_type": "text"
      },
      "source": [
        "For this coursework you will need to train a large network, therefore we recommend you work with Google Colaboratory, which provides free GPU time. You will need a Google account to do so. \n",
        "\n",
        "Please log in to your account and go to the following page: https://colab.research.google.com. Then upload this notebook.\n",
        "\n",
        "For GPU support, go to \"Edit\" -> \"Notebook Settings\", and select \"Hardware accelerator\" as \"GPU\".\n",
        "\n",
        "You will need to install pytorch by running the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rc7r58Dbqa4k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "d56377cd-7722-497a-9ca7-b9fe883e86d8"
      },
      "source": [
        "!pip install torch torchvision"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.17.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (6.2.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQpb-Qtsqa4r",
        "colab_type": "text"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NJCwSFCqa4s",
        "colab_type": "text"
      },
      "source": [
        "For this coursework you will implement one of the most commonly used model for image recognition tasks, the Residual Network. The architecture is introduced in 2015 by Kaiming He, et al. in the paper [\"Deep residual learning for image recognition\"](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf). \n",
        "<br>\n",
        "\n",
        "In a residual network, each block contains some convolutional layers, plus \"skip\" connections, which allow the activations to by pass a layer, and then be summed up with the activations of the skipped layer. The image below illustrates a building block in residual networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmokV89vqa4t",
        "colab_type": "text"
      },
      "source": [
        "![resnet-block](utils/resnet-block.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXaXxsmTqa4u",
        "colab_type": "text"
      },
      "source": [
        "Depending on the number of building blocks, resnets can have different architectures, for example ResNet-50, ResNet-101 and etc. Here you are required to build ResNet-18 to perform classification on the CIFAR-10 dataset, therefore your network will have the following architecture:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHQChkqnqa4v",
        "colab_type": "text"
      },
      "source": [
        "![resnet](utils/resnet.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CqNqUyBqa4w",
        "colab_type": "text"
      },
      "source": [
        "## Part 1 (40 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giQ8kzCJqa4x",
        "colab_type": "text"
      },
      "source": [
        "In this part, you will use basic pytorch operations to define the 2D convolution, max pooling operation, linear layer as well as 2d batch normalization. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlNs_GjLqa4y",
        "colab_type": "text"
      },
      "source": [
        "### YOUR TASK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTXyTko5qa4z",
        "colab_type": "text"
      },
      "source": [
        "- implement the forward pass for Conv2D, MaxPool2D, Linear and BatchNorm2d\n",
        "- You are **NOT** allowed to use the torch.nn modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8hk1JX9qa40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Conv2d(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 kernel_size,\n",
        "                 stride=1,\n",
        "                 padding=0,\n",
        "                 bias=True):\n",
        "\n",
        "        super(Conv2d, self).__init__()\n",
        "        \"\"\"\n",
        "        An implementation of a convolutional layer.\n",
        "\n",
        "        The input consists of N data points, each with C channels, height H and\n",
        "        width W. We convolve each input with F different filters, where each filter\n",
        "        spans all C channels and has height HH and width WW.\n",
        "\n",
        "        Parameters:\n",
        "        - w: Filter weights of shape (F, C, HH, WW)\n",
        "        - b: Biases, of shape (F,)\n",
        "        - kernel_size: Size of the convolving kernel\n",
        "        - stride: The number of pixels between adjacent receptive fields in the\n",
        "            horizontal and vertical directions.\n",
        "        - padding: The number of pixels that will be used to zero-pad the input.\n",
        "        \"\"\"\n",
        "\n",
        "        ########################################################################\n",
        "        # TODO: Define the parameters used in the forward pass                 #\n",
        "        ########################################################################\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        assert(type(in_channels) is int and type(out_channels) is int)\n",
        "        assert(type(stride) is int and type(padding) is int)\n",
        "        assert(type(bias) is bool)\n",
        "        assert(type(kernel_size) is int or type(kernel_size) is tuple)\n",
        "        if type(kernel_size) is tuple:\n",
        "            assert(len(kernel_size) == 2 and type(kernel_size[0]) is int and type(kernel_size[1]) is int)\n",
        "            self.kernel_size = kernel_size\n",
        "        else:\n",
        "            self.kernel_size = (kernel_size, kernel_size)\n",
        "        k = torch.tensor(1.0/in_channels)\n",
        "        w = torch.sqrt(k)*torch.randn((out_channels, in_channels, self.kernel_size[0], self.kernel_size[1]), requires_grad = True)\n",
        "        self.w = nn.Parameter(w)\n",
        "        b = torch.sqrt(k)*torch.randn(out_channels, requires_grad = True)\n",
        "        self.b = nn.Parameter(b)\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.bias = bias\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        ########################################################################\n",
        "        #                             END OF YOUR CODE                         #\n",
        "        ########################################################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "        - x: Input data of shape (N, C, H, W)\n",
        "        Output:\n",
        "        - out: Output data, of shape (N, F, H', W').\n",
        "        \"\"\"\n",
        "\n",
        "        ########################################################################\n",
        "        # TODO: Implement the forward pass                                     #\n",
        "        ########################################################################\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        \n",
        "        #Calculate the output shape\n",
        "        N = x.shape[0]\n",
        "        C = self.w.shape[0] #out channels\n",
        "        H_ = (x.shape[2]+2*self.padding-self.kernel_size[0])//self.stride+1\n",
        "        W_ = (x.shape[3]+2*self.padding-self.kernel_size[1])//self.stride+1\n",
        "        # reference: https://pytorch.org/docs/stable/nn.html?highlight=unfold#torch.nn.Unfold\n",
        "        # First Unfold the filter with the given size\n",
        "        x_unf = F.unfold(x, self.kernel_size, padding = self.padding, stride = self.stride)\n",
        "        # then we can use matrix multiplication to calculate convolution\n",
        "        out_unf = x_unf.transpose(1,2).matmul(self.w.view(self.w.size(0),-1).t()).transpose(1,2)\n",
        "        out = out_unf.view(N, C, H_, W_)\n",
        "        if self.bias:\n",
        "          bias = self.b.repeat(H_, W_, 1).T\n",
        "          out += bias\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        ########################################################################\n",
        "        #                             END OF YOUR CODE                         #\n",
        "        ########################################################################\n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xn1Azxp8qa44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MaxPool2d(nn.Module):\n",
        "    def __init__(self, kernel_size):\n",
        "        super(MaxPool2d, self).__init__()\n",
        "        \"\"\"\n",
        "        An implementation of a max-pooling layer.\n",
        "\n",
        "        Parameters:\n",
        "        - kernel_size: the size of the window to take a max over\n",
        "        \"\"\"\n",
        "        ########################################################################\n",
        "        # TODO: Define the parameters used in the forward pass                 #\n",
        "        ########################################################################\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        \n",
        "        # Check that kernel size is either an int or a tuple of two ints\n",
        "        assert(type(kernel_size) is int or type(kernel_size) is tuple)\n",
        "        if type(kernel_size) is tuple:\n",
        "            assert(len(kernel_size) == 2 and type(kernel_size[0]) is int and type(kernel_size[1]) is int)\n",
        "            self.kernel_size = kernel_size\n",
        "        else:\n",
        "            self.kernel_size = (kernel_size, kernel_size)\n",
        "\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        ########################################################################\n",
        "        #                             END OF YOUR CODE                         #\n",
        "        ########################################################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "        - x: Input data of shape (N, C, H, W)\n",
        "        Output:\n",
        "        - out: Output data, of shape (N, F, H', W').\n",
        "        \"\"\"\n",
        "        ########################################################################\n",
        "        # TODO: Implement the forward pass                                     #\n",
        "        ########################################################################\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "        # Get the size of the kernel\n",
        "        kh, kw = self.kernel_size\n",
        "        # Unfold the input and shape it to the desired shape\n",
        "        x1 = F.unfold(x, kernel_size = self.kernel_size, stride = self.kernel_size)\n",
        "        x1 = x1.view(x1.shape[0], x.shape[1], -1, x1.shape[2]) #x1.shape[0], -1, self.kernel_size**2, x1.shape[2]\n",
        "        max_pool, _ = x1.max(axis = 2)\n",
        "        # Calculate output shape\n",
        "        H_ = -int(-(x.shape[2]-kh+1)/kh)\n",
        "        W_ = -int(-(x.shape[3]-kw+1)/kw)\n",
        "        out = max_pool.view(x.shape[0], x.shape[1], H_, W_)\n",
        "\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        ########################################################################\n",
        "        #                             END OF YOUR CODE                         #\n",
        "        ########################################################################\n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhN_89Tnqa48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Linear(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, bias=True):\n",
        "        super(Linear, self).__init__()\n",
        "        \"\"\"\n",
        "        An implementation of a Linear layer.\n",
        "\n",
        "        Parameters:\n",
        "        - weight: the learnable weights of the module of shape (in_channels, out_channels).\n",
        "        - bias: the learnable bias of the module of shape (out_channels).\n",
        "        \"\"\"\n",
        "        ########################################################################\n",
        "        # TODO: Define the parameters used in the forward pass                 #\n",
        "        ########################################################################\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        assert(type(in_channels) is int and type(out_channels) is int and type(bias) is bool)\n",
        "        k = torch.tensor(1.0/in_channels)\n",
        "        weight = torch.randn((in_channels, out_channels), requires_grad = True)*torch.sqrt(k)\n",
        "        self.weight = nn.Parameter(weight)\n",
        "        self.use_bias = False\n",
        "        if bias:\n",
        "            bias = torch.randn(out_channels, requires_grad = True)*torch.sqrt(k)\n",
        "            self.bias = nn.Parameter(bias)\n",
        "            self.use_bias = True\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        ########################################################################\n",
        "        #                             END OF YOUR CODE                         #\n",
        "        ########################################################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "        - x: Input data of shape (N, *, H) where * means any number of additional\n",
        "        dimensions and H = in_channels\n",
        "        Output:\n",
        "        - out: Output data of shape (N, *, H') where * means any number of additional\n",
        "        dimensions and H' = out_channels\n",
        "        \"\"\"\n",
        "        ########################################################################\n",
        "        # TODO: Implement the forward pass                                     #\n",
        "        ########################################################################\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "        out = torch.matmul(x, self.weight)\n",
        "        if self.use_bias:\n",
        "            out = out + self.bias\n",
        "\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        ########################################################################\n",
        "        #                             END OF YOUR CODE                         #\n",
        "        ########################################################################\n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bFaQzY_qa4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BatchNorm2d(nn.Module):\n",
        "    def __init__(self, num_features, eps=1e-05, momentum=0.1):\n",
        "        super(BatchNorm2d, self).__init__()\n",
        "        \"\"\"\n",
        "        An implementation of a Batch Normalization over a mini-batch of 2D inputs.\n",
        "\n",
        "        The mean and standard-deviation are calculated per-dimension over the\n",
        "        mini-batches and gamma and beta are learnable parameter vectors of\n",
        "        size num_features.\n",
        "\n",
        "        Parameters:\n",
        "        - num_features: C from an expected input of size (N, C, H, W).\n",
        "        - eps: a value added to the denominator for numerical stability. Default: 1e-5\n",
        "        - momentum: momentum - the value used for the running_mean and running_var\n",
        "        computation. Default: 0.1\n",
        "        - gamma: the learnable weights of shape (num_features).\n",
        "        - beta: the learnable bias of the module of shape (num_features).\n",
        "        \"\"\"\n",
        "        ########################################################################\n",
        "        # TODO: Define the parameters used in the forward pass                 #\n",
        "        ########################################################################\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        assert(type(num_features) is int)\n",
        "        assert(type(eps) is float and type(momentum) is float)\n",
        "        assert(momentum >= 0 and momentum <= 1)\n",
        "        self.num_features = num_features\n",
        "        self.eps = eps\n",
        "        self.momentum = momentum\n",
        "        # gamma and beta are set according to the documentation of pytorch BatchNorm2d\n",
        "        # implementation: https://pytorch.org/docs/stable/nn.html?highlight=maxpool#torch.nn.AdaptiveMaxPool2d\n",
        "        self.gamma = nn.Parameter(torch.ones(num_features, requires_grad = True))\n",
        "        self.beta = nn.Parameter(torch.zeros(num_features, requires_grad = True))\n",
        "        # Initialize running mean and vars\n",
        "        self.running_mean = torch.zeros(num_features)\n",
        "        self.running_var = torch.ones(num_features)\n",
        "        # flag for training\n",
        "        self.training = True\n",
        "\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        ########################################################################\n",
        "        #                             END OF YOUR CODE                         #\n",
        "        ########################################################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        During training this layer keeps running estimates of its computed mean and\n",
        "        variance, which are then used for normalization during evaluation.\n",
        "        Input:\n",
        "        - x: Input data of shape (N, C, H, W)\n",
        "        Output:\n",
        "        - out: Output data of shape (N, C, H, W) (same shape as input)\n",
        "        \"\"\"\n",
        "        ########################################################################\n",
        "        # TODO: Implement the forward pass                                     #\n",
        "        #       (be aware of the difference for training and testing)          #\n",
        "        ########################################################################\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        \n",
        "        # Very strange behavior compared to pytorch BatchNorm2D\n",
        "        if self.training:\n",
        "            mean = x.mean([0,2,3])\n",
        "            var = x.var([0,2,3])\n",
        "            self.running_mean = (1-self.momentum)*self.running_mean + self.momentum*mean\n",
        "            self.running_var = (1-self.momentum)*self.running_var + self.momentum*var\n",
        "            # Change the variance to biased\n",
        "            var = x.var([0,2,3], unbiased = False)\n",
        "        else:\n",
        "            mean = self.running_mean\n",
        "            var = self.running_var\n",
        "        x = (x-mean.view(1,-1,1,1))/torch.sqrt(var+self.eps).view(1,-1,1,1)*self.gamma.view(1,-1,1,1) + self.beta.view(1,-1,1,1)\n",
        "        # Don't know how to see if training\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        ########################################################################\n",
        "        #                             END OF YOUR CODE                         #\n",
        "        ########################################################################\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5DkQ-uFqa5C",
        "colab_type": "text"
      },
      "source": [
        "## Part 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGtjqnTWqa5E",
        "colab_type": "text"
      },
      "source": [
        "In this part, you will train a ResNet-18 defined on the CIFAR-10 dataset. Code for training and evaluation are provided. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7voMlesqa5F",
        "colab_type": "text"
      },
      "source": [
        "### Your Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omEg2Hk7qa5G",
        "colab_type": "text"
      },
      "source": [
        "1. Train your network to achieve the best possible test set accuracy after a maximum of 10 epochs of training.\n",
        "\n",
        "2. You can use techniques such as optimal hyper-parameter searching, data pre-processing\n",
        "\n",
        "3. If necessary, you can also use another optimizer\n",
        "\n",
        "4. **Answer the following question:**\n",
        "Given such a network with a large number of trainable parameters, and a training set of a large number of data, what do you think is the best strategy for hyperparameter searching? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCCKvDuTTZbK",
        "colab_type": "text"
      },
      "source": [
        "**Answer for 4**. For a problem of such a big parameter space and large training data, we need to consider the time we have when developing a strategy for hyperparameter searching. A simple grid search may be too time consuming in such a case, especially when the hardware's ability is limited. One possible way to find the best optimal hyperparameter is to use Bayesian optimization on the hyperparameters. Another approach is to use genetic algorithms to simulate an evolution of the hyperparameters, although this may not be as mathematically rigorous as using Bayesian optimization. In this coursework I tried to design a genetic algorithm to find the best hyperparameters to feed into the Adam optimiser. The performance of a set of hyperparameters are evaluated on a validation set and afterwards we find the best set of hyperparameters and evaluate its performance on the testing set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmmwiO0Zqa5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.nn import Conv2d, MaxPool2d\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97b7qV8sqa5K",
        "colab_type": "text"
      },
      "source": [
        "Next, we define ResNet-18:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TTiVdnyqa5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define resnet building blocks\n",
        "\n",
        "class ResidualBlock(nn.Module): \n",
        "    def __init__(self, inchannel, outchannel, stride=1): \n",
        "        \n",
        "        super(ResidualBlock, self).__init__() \n",
        "        \n",
        "        self.left = nn.Sequential(Conv2d(inchannel, outchannel, kernel_size=3, \n",
        "                                         stride=stride, padding=1, bias=False), \n",
        "                                  nn.BatchNorm2d(outchannel), \n",
        "                                  nn.ReLU(inplace=True), \n",
        "                                  Conv2d(outchannel, outchannel, kernel_size=3, \n",
        "                                         stride=1, padding=1, bias=False), \n",
        "                                  nn.BatchNorm2d(outchannel)) \n",
        "        \n",
        "        self.shortcut = nn.Sequential() \n",
        "        \n",
        "        if stride != 1 or inchannel != outchannel: \n",
        "            \n",
        "            self.shortcut = nn.Sequential(Conv2d(inchannel, outchannel, \n",
        "                                                 kernel_size=1, stride=stride, \n",
        "                                                 padding = 0, bias=False), \n",
        "                                          nn.BatchNorm2d(outchannel) ) \n",
        "            \n",
        "    def forward(self, x): \n",
        "        \n",
        "        out = self.left(x) \n",
        "        \n",
        "        out += self.shortcut(x) \n",
        "        \n",
        "        out = F.relu(out) \n",
        "        \n",
        "        return out\n",
        "\n",
        "\n",
        "    \n",
        "    # define resnet\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    \n",
        "    def __init__(self, ResidualBlock, num_classes = 10):\n",
        "        \n",
        "        super(ResNet, self).__init__()\n",
        "        \n",
        "        self.inchannel = 64\n",
        "        self.conv1 = nn.Sequential(Conv2d(3, 64, kernel_size = 3, stride = 1,\n",
        "                                            padding = 1, bias = False), \n",
        "                                  nn.BatchNorm2d(64), \n",
        "                                  nn.ReLU())\n",
        "        \n",
        "        self.layer1 = self.make_layer(ResidualBlock, 64, 2, stride = 1)\n",
        "        self.layer2 = self.make_layer(ResidualBlock, 128, 2, stride = 2)\n",
        "        self.layer3 = self.make_layer(ResidualBlock, 256, 2, stride = 2)\n",
        "        self.layer4 = self.make_layer(ResidualBlock, 512, 2, stride = 2)\n",
        "        self.maxpool = MaxPool2d(4)\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "        \n",
        "    \n",
        "    def make_layer(self, block, channels, num_blocks, stride):\n",
        "        \n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        \n",
        "        layers = []\n",
        "        \n",
        "        for stride in strides:\n",
        "            \n",
        "            layers.append(block(self.inchannel, channels, stride))\n",
        "            \n",
        "            self.inchannel = channels\n",
        "            \n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "    \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        \n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        \n",
        "        x = self.maxpool(x)\n",
        "        \n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        x = self.fc(x)\n",
        "        \n",
        "        return x\n",
        "    \n",
        "    \n",
        "def ResNet18():\n",
        "    return ResNet(ResidualBlock)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmDPlMjaqa5O",
        "colab_type": "text"
      },
      "source": [
        "### Loading dataset\n",
        "We will import images from the [torchvision.datasets](https://pytorch.org/docs/stable/torchvision/datasets.html) library <br>\n",
        "First, we need to define the alterations (transforms) we want to perform to our images - given that transformations are applied when importing the data. <br>\n",
        "Define the following transforms using the torchvision.datasets library -- you can read the transforms documentation [here](https://pytorch.org/docs/stable/torchvision/transforms.html): <br>\n",
        "1. Convert images to tensor\n",
        "2. Normalize mean and std of images with values:mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvRbzkdSqa5P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "\n",
        "import torchvision.datasets as dset\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torchvision.transforms as T\n",
        "\n",
        "##############################################################\n",
        "#                       YOUR CODE HERE                       #       \n",
        "##############################################################\n",
        "\n",
        "transform = T.Compose([\n",
        "           T.RandomRotation(20),   #We add RandomRotation and RandomHorizontalFlip to create a variety of data\n",
        "           T.RandomCrop(size=32, padding=4),\n",
        "           T.RandomHorizontalFlip(),\n",
        "           T.ToTensor(),\n",
        "           T.Normalize(mean = [0.4914, 0.4822, 0.4465], std = [0.2023, 0.1994, 0.2010])\n",
        "])\n",
        "\n",
        "##############################################################\n",
        "#                       END OF YOUR CODE                     #\n",
        "##############################################################\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2H3ZLK7oqa5T",
        "colab_type": "text"
      },
      "source": [
        "Now load the dataset using the transform you defined above, with batch_size = 64<br>\n",
        "You can check the documentation [here](https://pytorch.org/docs/stable/torchvision/datasets.html)\n",
        "Then create data loaders (using DataLoader from torch.utils.data) for the training and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alN6UIETqa5U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "c1e9eaaa53e64837985eac1c1dbc17b0",
            "084c1452157f43a29ee0f14bf02dd744",
            "d546dee506f74f16a65459ff85c0a55f",
            "1298168d3ba8432ab950690f26ca6787",
            "0fbd01f094164c159430e78162e9f655",
            "2f5e287bc8ba4500ad9285c6efc1e138",
            "df76a81266bc40b68f64fca82072d625",
            "3f19db64f4b54dde88854f0f85bd0079"
          ]
        },
        "outputId": "04b1f594-331f-4fa1-f953-b509a73f742f"
      },
      "source": [
        "\n",
        "##############################################################\n",
        "#                       YOUR CODE HERE                       #       \n",
        "##############################################################\n",
        "\n",
        "data_dir = './data'\n",
        "\n",
        "train_num = 49000\n",
        "val_num = 1000\n",
        "\n",
        "cifar10_train = dset.CIFAR10(data_dir, train = True, transform = transform, download = True)\n",
        "data_train = DataLoader(cifar10_train, batch_size = 64, sampler= sampler.SubsetRandomSampler(range(train_num)), num_workers = 4)\n",
        "\n",
        "data_val = DataLoader(cifar10_train, batch_size = 64, sampler=sampler.SubsetRandomSampler(range(train_num, train_num + val_num)), num_workers = 4)\n",
        "\n",
        "cifar10_test = dset.CIFAR10(data_dir, train = False, transform = transform, download = True)\n",
        "data_test = DataLoader(cifar10_test, batch_size = 64)\n",
        "\n",
        "\n",
        "##############################################################\n",
        "#                       END OF YOUR CODE                     #       \n",
        "##############################################################\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c1e9eaaa53e64837985eac1c1dbc17b0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5pNHPKuqa5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "USE_GPU = True\n",
        "dtype = torch.float32 \n",
        "\n",
        "if USE_GPU and torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    \n",
        "    \n",
        "\n",
        "print_every = 100\n",
        "def check_accuracy(loader, model):\n",
        "    # function for test accuracy on validation and test set\n",
        "    \n",
        "    if loader.dataset.train:\n",
        "        print('Checking accuracy on validation set')\n",
        "    else:\n",
        "        print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()  # set model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device=device, dtype=dtype)  # move to device\n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "            scores = model(x)\n",
        "            _, preds = scores.max(1)\n",
        "            num_correct += (preds == y).sum()\n",
        "            num_samples += preds.size(0)\n",
        "        acc = float(num_correct) / num_samples\n",
        "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "\n",
        "        \n",
        "\n",
        "def train_part(model, optimizer, epochs=1, print_ = True):\n",
        "    \"\"\"\n",
        "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
        "    \n",
        "    Inputs:\n",
        "    - model: A PyTorch Module giving the model to train.\n",
        "    - optimizer: An Optimizer object we will use to train the model\n",
        "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
        "    \n",
        "    Returns: Nothing, but prints model accuracies during training.\n",
        "    \"\"\"\n",
        "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
        "    for e in range(epochs):\n",
        "        if print_:\n",
        "          print(len(loader_train))\n",
        "        for t, (x, y) in enumerate(loader_train):\n",
        "            model.train()  # put model to training mode\n",
        "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "\n",
        "            scores = model(x)\n",
        "            loss = F.cross_entropy(scores, y)\n",
        "\n",
        "            # Zero out all of the gradients for the variables which the optimizer\n",
        "            # will update.\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            # Update the parameters of the model using the gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            if t % print_every == 0 and print_ == True:\n",
        "                print('Epoch: %d, Iteration %d, loss = %.4f' % (e, t, loss.item()))\n",
        "                check_accuracy(loader_val, model)\n",
        "                print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVwVh0UTdCgH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here we use genetic algorithm to find the best data\n",
        "#Step 1. define relevant functions\n",
        "def return_accuracy(loader, model, device = torch.device('cuda')):\n",
        "    # function for test accuracy on validation and test set \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()  # set model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device=device, dtype=dtype)  # move to device\n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "            scores = model(x)\n",
        "            _, preds = scores.max(1)\n",
        "            num_correct += (preds == y).sum()\n",
        "            num_samples += preds.size(0)\n",
        "        acc = float(num_correct) / num_samples\n",
        "        return acc\n",
        "\n",
        "def eval_geno(genotype, bit):\n",
        "  feat = genotype//(2**bit)\n",
        "  new_geno = genotype - 2**bit*feat\n",
        "  return feat, new_geno\n",
        "\n",
        "def pheno(genotype, genom_l = 15):\n",
        "  assert(type(genotype) == int)\n",
        "  assert(0<=genotype<2**genom_l)\n",
        "  # Get ams grad\n",
        "  geno_ams, genotype = eval_geno(genotype, 14)\n",
        "  amsgrad = geno_ams > 0\n",
        "  # Get learning rate\n",
        "  geno_lr, genotype = eval_geno(genotype, 11)\n",
        "  lr = 2**geno_lr*1e-5\n",
        "  # Get beta 1\n",
        "  geno_b1, genotype = eval_geno(genotype, 8)\n",
        "  b1 = 0.75+0.03*geno_b1\n",
        "  # Get beta 2\n",
        "  geno_b2, genotype = eval_geno(genotype, 5)\n",
        "  b2 = 0.997+0.0003*geno_b2\n",
        "  # Get eps\n",
        "  geno_eps, genotype = eval_geno(genotype, 3)\n",
        "  eps = 10**(-9+geno_eps)\n",
        "  geno_wdk, genotype = eval_geno(genotype, 0)\n",
        "  weight_decay = 0.06*geno_wdk\n",
        "  return lr, (b1, b2), eps, weight_decay, amsgrad\n",
        "\n",
        "def breed(parents, geno_l = 15):\n",
        "  splits = np.random.randint(0, geno_l)\n",
        "  #np.random.shuffle(parents)\n",
        "  p_0 = (2**splits)*parents[0]//(2**splits)\n",
        "  p_1 = parents[1] - (2**splits)*parents[1]//(2**splits)\n",
        "  child = p_0+p_1\n",
        "  #mutate\n",
        "  for i in range(12):\n",
        "    if np.random.rand() < 0.1:\n",
        "      bit = (0.5-child//(2**i)%2)\n",
        "      child += bit*2**(i+1)\n",
        "  return child"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXLFNzWAeLo_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "50752529-a2a7-4d17-bb43-011de3aeacb5"
      },
      "source": [
        "loader_train = data_train\n",
        "loader_val = data_val\n",
        "\n",
        "# Testing different params\n",
        "best_geno = None\n",
        "best_accuracy = 0\n",
        "# create 10 genotypes\n",
        "geno_length = 15\n",
        "genos = np.array([29880, 31928, 30904, 21529, 21969, 2473, 19267, 19640, 17215, 27730, 15423, 31992,\n",
        " 19047, 25413, 1108])#np.random.randint(0, 2**(geno_length), size = 15)\n",
        "num_of_generations = 10\n",
        "acc = np.array([0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0, 0.0, 0.0, 0.0, 0.0])\n",
        "for i in range(num_of_generations):\n",
        "  print('Heres a new generation ...')\n",
        "  s = 3\n",
        "  for gen in genos[3:]:\n",
        "    lr, betas, eps, weight_decay, amsgrad = pheno(int(gen))\n",
        "    # define and train the network\n",
        "    model = ResNet18()\n",
        "    optimizer = optim.Adam(model.parameters(), lr = lr, betas = betas , eps = eps, weight_decay = weight_decay, amsgrad = amsgrad)\n",
        "    train_part(model, optimizer, epochs = 10, print_ = False)\n",
        "    acc[s] = return_accuracy(loader_val, model, device = device)\n",
        "    s += 1\n",
        "  genos = genos[acc.argsort()[::-1]]\n",
        "  acc[::-1].sort()\n",
        "  print(acc)\n",
        "  \n",
        "  print(genos)\n",
        "  #keep top 3 and use these to mute\n",
        "  for j in range(3,15):\n",
        "    parents = np.random.choice(genos[:3], 2)\n",
        "    genos[j] = breed(parents)\n",
        "  if acc.max() > best_accuracy:\n",
        "    best_accuracy = acc.max()\n",
        "    best_geno = genos[0]\n",
        "  print('Generation: ',i+1,' average acc: ', acc.mean(), ' max acc: ', acc.max())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Heres a new generation ...\n",
            "[0.834 0.744 0.737 0.729 0.727 0.711 0.695 0.677 0.675 0.533 0.451 0.079\n",
            " 0.    0.    0.   ]\n",
            "[31992 19047 21529 19267  2473 21969  1108 17215 19640 25413 27730 15423\n",
            " 30904 31928 29880]\n",
            "Generation:  1  average acc:  0.5061333333333332  max acc:  0.834\n",
            "Heres a new generation ...\n",
            "[0.837 0.834 0.833 0.759 0.758 0.75  0.744 0.738 0.737 0.734 0.73  0.728\n",
            " 0.718 0.201 0.174]\n",
            "[31992 31992 30968 19047 21529 19047 19047 19047 21529 21643 19047 21561\n",
            " 19043 31986 31868]\n",
            "Generation:  2  average acc:  0.685  max acc:  0.837\n",
            "Heres a new generation ...\n",
            "[0.838 0.837 0.834 0.833 0.833 0.83  0.828 0.828 0.828 0.819 0.818 0.817\n",
            " 0.816 0.245 0.167]\n",
            "[31984 31992 31992 31864 30968 30904 30968 31976 30968 29304 31992 30832\n",
            " 31992 32249 31996]\n",
            "Generation:  3  average acc:  0.7447333333333332  max acc:  0.838\n",
            "Heres a new generation ...\n",
            "[0.838 0.837 0.835 0.834 0.833 0.833 0.83  0.826 0.825 0.818 0.818 0.341\n",
            " 0.187 0.181 0.164]\n",
            "[31984 31992 31848 31992 31992 30968 31992 31992 31992 32496 29944 29946\n",
            " 30971 31932 32251]\n",
            "Generation:  4  average acc:  0.6666666666666665  max acc:  0.838\n",
            "Heres a new generation ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqNVsZSAqa5a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "5e2e9058-2273-42f7-c501-7ac39f60c62a"
      },
      "source": [
        "# code for optimising your network performance\n",
        "\n",
        "##############################################################\n",
        "#                       YOUR CODE HERE                       #       \n",
        "##############################################################\n",
        "\n",
        "# Here we use the best hyperparameters found by genetic algorithm to train on the whole test set\n",
        "\n",
        "data_train = DataLoader(cifar10_train, batch_size = 64, sampler=sampler.SubsetRandomSampler(range(train_num + val_num)), num_workers = 4)\n",
        "\n",
        "loader_train = data_train\n",
        "loader_test = data_test\n",
        "\n",
        "lr, betas, eps, weight_decay, amsgrad = pheno(29880)#pheno(int(genos[0])) \n",
        "\n",
        "##############################################################\n",
        "#                       END OF YOUR CODE                     #\n",
        "##############################################################\n",
        "\n",
        "\n",
        "# define and train the network\n",
        "model = ResNet18()\n",
        "#optimizer = optim.Adam(model.parameters(), lr = lr, betas = betas , eps = eps, weight_decay = weight_decay, amsgrad = amsgrad)\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.0056, amsgrad = True)\n",
        "train_part(model, optimizer, epochs = 10)\n",
        "\n",
        "\n",
        "# report test set accuracy\n",
        "\n",
        "check_accuracy(loader_test, model)\n",
        "\n",
        "\n",
        "# save the model\n",
        "torch.save(model.state_dict(), 'model.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782\n",
            "Epoch: 0, Iteration 0, loss = 4.6675\n",
            "\n",
            "Epoch: 0, Iteration 100, loss = 2.1702\n",
            "\n",
            "Epoch: 0, Iteration 200, loss = 2.0308\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZADjCwAqa5d",
        "colab_type": "text"
      },
      "source": [
        "## Part 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr71YkTwqa5e",
        "colab_type": "text"
      },
      "source": [
        "The code provided below will allow you to visualise the feature maps computed by different layers of your network. Run the code (install matplotlib if necessary) and **answer the following questions**: \n",
        "\n",
        "1. Compare the feature maps from low-level layers to high-level layers, what do you observe? \n",
        "\n",
        "2. Use the training log, reported test set accuracy and the feature maps, analyse the performance of your network. If you think the performance is sufficiently good, explain why; if not, what might be the problem and how can you improve the performance?\n",
        "\n",
        "3. What are the other possible ways to analyse the performance of your network?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrlcpwHwqa5f",
        "colab_type": "text"
      },
      "source": [
        "**YOUR ANSWER FOR PART 3 HERE**\n",
        "\n",
        "Answers\n",
        "1. For the low level layers we see that some sort of structure is captured after the convolution operations. We can see the contour like features and some high intensity regions in the first layers of the network. As the data progress to high-level layers, we see some pixels have higher intensity than others, and the output images look like an activation map with individual pixels activated. The overall structure of the original image becomes unobservable and the functions are more abstract.\n",
        "2. The test set accuracy achieves 87% after 10 episodes. The result is acceptable but unsatisfying. In oberving ways to improve performance, we see that the loss seems to be decreasing still around 10 epochs. This indicates that training on more epochs may further improve performance. When we compare the feature maps we obtained with other published feature maps (https://arxiv.org/pdf/1311.2901.pdf). We see that our feature maps are rather \"unobvious\", thus we may not be learning well enough representations for each feature. As mentioned above we may increase the number of epochs in training or increase the complexity of our neural network model.\n",
        "3. Other than measuring test set accuracy, we can also use the average loss on the test set to evaluate the performance. For more detailed analysis we can create a confusion matrix for the testing set, measure the precision, recall, F1-scores and other measures. Looking at the confusion matrix is especially important if we are dealing with unbalanced datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Z8KFudUqa5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install matplotlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "\n",
        "activation = {}\n",
        "def get_activation(name):\n",
        "    def hook(model, input, output):\n",
        "        activation[name] = output.detach()\n",
        "    return hook\n",
        "\n",
        "vis_labels = ['conv1', 'layer1', 'layer2', 'layer3', 'layer4']\n",
        "\n",
        "for l in vis_labels:\n",
        "\n",
        "    getattr(model, l).register_forward_hook(get_activation(l))\n",
        "        \n",
        "data, _ = cifar10_test[0]\n",
        "data = data.unsqueeze_(0).to(device = device, dtype = dtype)\n",
        "\n",
        "output = model(data)\n",
        "\n",
        "\n",
        "\n",
        "for idx, l in enumerate(vis_labels):\n",
        "\n",
        "    act = activation[l].squeeze()\n",
        "\n",
        "    if idx < 2:\n",
        "        ncols = 8\n",
        "    else:\n",
        "        ncols = 32\n",
        "        \n",
        "    nrows = act.size(0) // ncols\n",
        "    \n",
        "    fig, axarr = plt.subplots(nrows, ncols)\n",
        "    fig.suptitle(l)\n",
        "\n",
        "\n",
        "    for i in range(nrows):\n",
        "        for j in range(ncols):\n",
        "            axarr[i, j].imshow(act[i * nrows + j].cpu())\n",
        "            axarr[i, j].axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}